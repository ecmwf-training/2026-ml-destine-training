{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3620b1",
   "metadata": {},
   "source": [
    "# Hands-on: Training the AIFS-ENS with Anemoi\n",
    "\n",
    "In this tutorial we will learn how to train the AIFS-ENS (ensemble) model using the anemoi packages. We'll focus on the CRPS (Continuous Ranked Probability Score) based training approach, which is specifically designed for ensemble weather forecasting.\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand the key differences between deterministic and ensemble CRPS training\n",
    "- Learn how to configure the anemoi training pipeline for ensemble models\n",
    "- Build a minimal training configuration step-by-step\n",
    "- Execute a short training run to verify everything works\n",
    "\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Anemoi docu: CRPS-based training](https://anemoi.readthedocs.io/projects/training/en/latest/user-guide/kcrps-set-up.html)\n",
    "- [Anemoi Documentation](https://anemoi.readthedocs.io/projects/training/en/latest/)\n",
    "- [Lang et al. 2024](http://arxiv.org/abs/2412.15832)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91944edf",
   "metadata": {},
   "source": [
    "## Background: What is CRPS Training?\n",
    "\n",
    "The **Continuous Ranked Probability Score (CRPS)** is a proper scoring rule for evaluating probabilistic forecasts. In the context of ensemble weather forecasting, CRPS training allows us to train models that produce multiple ensemble members, each representing a different possible future state of the atmosphere.\n",
    "\n",
    "<img src=\"_resources/aifs-crps_sketch.png\" alt=\"CRPS Sketch\" width=\"900\">\n",
    "\n",
    "### Why Ensemble Training?\n",
    "\n",
    "- **Uncertainty Quantification**: Each ensemble member represents a different possible future\n",
    "- **Probabilistic Forecasting**: Provides uncertainty estimates alongside predictions\n",
    "- **Better Skill Scores**: Often outperforms deterministic models in terms of skill metrics\n",
    "- **Operational Use**: Essential for weather services that need to communicate forecast uncertainty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38bbd5",
   "metadata": {},
   "source": [
    "## CRPS Training in Anemoi\n",
    "\n",
    "### Key Differences: Deterministic vs CRPS Training\n",
    "\n",
    "The main components of the training pipeline need to be modified when switching from deterministic to ensemble CRPS training:\n",
    "\n",
    "| Component | Deterministic | CRPS |\n",
    "|-----------|---------------|------|\n",
    "| **Forecaster** | `GraphForecaster` | `GraphEnsForecaster` |\n",
    "| **Strategy** | `DDPGroupStrategy` | `DDPEnsGroupStrategy` |\n",
    "| **Training Loss** | `WeightedMSELoss` | `AlmostFairKernelCRPS` |\n",
    "| **Model** | `AnemoiModelEncProcDec` | `AnemoiEnsModelEncProcDec` |\n",
    "| **Datamodule** | `AnemoiDatasetsDataModule` | `AnemoiEnsDatasetsDataModule` |\n",
    "\n",
    "\n",
    "#### The AlmostFairKernelCRPS Loss\n",
    "\n",
    "The training uses the AlmostFairKernelCRPS loss function, which combines the traditional CRPS with a \"fair\" version:\n",
    "\n",
    "$$\\text{afCRPS}_\\alpha := \\alpha\\text{fCRPS} + (1-\\alpha)\\text{CRPS}$$\n",
    "\n",
    "Where $\\alpha$ is a trade-off parameter between the CRPS and the fair CRPS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc72ee",
   "metadata": {},
   "source": [
    "## Building Our Training Config\n",
    "\n",
    "Now we'll examine our training configuration step-by-step, highlighting the key differences from deterministic training. We have a minimal configuration file ready that we'll load and examine section by section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0834480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing the necessary modules\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "# Load our minimal configuration file\n",
    "config_path = Path(\"configs/aifs_ens_minimal.yaml\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2b496",
   "metadata": {},
   "source": [
    "### Step 1: Hardware Configuration\n",
    "\n",
    "The hardware configuration needs to specify the number of GPUs per ensemble, which is crucial for the ensemble training strategy.\n",
    "\n",
    "**Key Points:**\n",
    "- `num_gpus_per_ensemble`: Number of GPUs to use per ensemble (typically 1 for small setups)\n",
    "- `num_gpus_per_model`: Number of GPUs per model instance\n",
    "- Total ensemble members = `ensemble_size_per_device` × `num_gpus_per_ensemble` (we'll set this later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the hardware configuration section\n",
    "print(\"Hardware Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(config['hardware'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3957c047",
   "metadata": {},
   "source": [
    "### Step 2: Datamodule Configuration\n",
    "\n",
    "For ensemble training, we need to use the `AnemoiEnsDatasetsDataModule` instead of the regular datamodule. This handles ensemble data loading and can work with either:\n",
    "- Single initial conditions for all ensemble members\n",
    "- Perturbed initial conditions (if available in your dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00612cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Datamodule configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(config['datamodule'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8f6d1",
   "metadata": {},
   "source": [
    "### Step 3: Model Configuration\n",
    "\n",
    "Key model changes for CRPS-based training are:\n",
    "\n",
    "1. **Ensemble Model Class**: Uses `AnemoiEnsModelEncProcDec` instead of `AnemoiModelEncProcDec`\n",
    "\n",
    "2. **Noise Injector**: Each ensemble member samples random noise at every time step:\n",
    "   ```yaml\n",
    "   noise_injector:\n",
    "     _target_: anemoi.models.layers.ensemble.NoiseConditioning\n",
    "     noise_std: 1\n",
    "     noise_channels_dim: 4\n",
    "     noise_mlp_hidden_dim: 32\n",
    "     inject_noise: True\n",
    "   ```\n",
    "\n",
    "3. **Conditional Layer Normalization**: The processor uses `ConditionalLayerNorm` instead of regular `LayerNorm` to condition the latent space on the noise:\n",
    "   ```yaml\n",
    "   processor:\n",
    "     layer_kernels:\n",
    "       LayerNorm:\n",
    "         _target_: anemoi.models.layers.normalization.ConditionalLayerNorm\n",
    "         normalized_shape: ${model.num_channels}\n",
    "         condition_shape: ${model.noise_injector.noise_channels_dim}\n",
    "   ```\n",
    "\n",
    "   Unlike standard layer normalization that normalizes features independently, conditional layer normalization allows the normalization to be conditioned on additional information (in this case, noise vectors).\n",
    "    - Each ensemble member gets a unique noise vector at every time step\n",
    "    - This noise is embedded and used to condition the layer normalization in the processor\n",
    "    - The conditioning allows the same model weights to produce different outputs for different ensemble members\n",
    "    - This creates diversity in the ensemble predictions while sharing computational resources\n",
    "\n",
    "\n",
    "This noise injection and conditioning is what allows each ensemble member to produce different predictions while sharing the same model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model configuration section\n",
    "print(\"Model Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "print(yaml.dump(config['model'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f38c4",
   "metadata": {},
   "source": [
    "### Step 4: Training Configuration\n",
    "\n",
    "Now we configure the training parameters, strategy, and loss function for ensemble training.\n",
    "\n",
    "**Key Training Parameters:**\n",
    "\n",
    "1. **Model Task**: Set to `GraphEnsForecaster` (handled by the `ensemble` training default)\n",
    "2. **Ensemble Size**: `ensemble_size_per_device: 2` means 2 ensemble members per device. Thus, the **Total Ensemble Members** is:\n",
    "    ```\n",
    "   ensemble_size_per_device × num_nodes x num_gpus_per_node / ( num_gpus_per_member x num_gpus_per_mod) = 2 × 1 x 1 / (1 x 1) = 2 members\n",
    "   ```\n",
    "   \n",
    "3. **Strategy**: Uses `DDPEnsGroupStrategy` (handled by the `ensemble` training default)\n",
    "4. **Loss Function**: `AlmostFairKernelCRPS` with `alpha=1.0` (pure fair CRPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61009d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the training configuration section\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "print(yaml.dump(config['training'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c32803",
   "metadata": {},
   "source": [
    "## Training Execution\n",
    "\n",
    "Now that we have our configuration ready, let's execute the training. We'll run a short training session to verify everything works correctly by running,\n",
    "\n",
    "```bash\n",
    "anemoi-training train --config-path . --config-name aifs_ens_minimal_config\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a7635-a840-40cb-bd77-1b3305136a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys, os \n",
    "\n",
    "# Set environment variables\n",
    "os.environ['ANEMOI_BASE_SEED'] = '42'\n",
    "os.environ['POSSIBLE_USER_WARNINGS'] = 'off'\n",
    "os.environ['TORCH_LOGS'] = \"-dynamo,-inductor\"\n",
    "\n",
    "# Execute the training using subprocess\n",
    "print(\"Starting AIFS-ENS training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    [\n",
    "        \"anemoi-training\", \"train\", \n",
    "        \"--config-path\", \"/home/student/2025-ml-training/6-Anemoi/configs\", \n",
    "        \"--config-name\", \"aifs_ens_minimal.yaml\"\n",
    "    ], \n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,  # Merge stderr into stdout\n",
    "    text=True,\n",
    "    bufsize=1,  # Line buffered\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "# Stream output\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    if line:\n",
    "        print(line.rstrip())  # Print immediately to Jupyter cell\n",
    "\n",
    "# Wait for completion\n",
    "return_code = process.wait()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "if return_code == 0:\n",
    "    print(\"✓ Training completed successfully!\")\n",
    "else:\n",
    "    print(f\"❌ Training failed with return code {return_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806adfa8",
   "metadata": {},
   "source": [
    "## Monitoring and Results\n",
    "\n",
    "### MLflow logging\n",
    "\n",
    "Several metrics and parameters are logged during training. Here, we use MLflow to log results offline. \n",
    "\n",
    "In the following we use the MLflow API to plot some key metrics during training, such as:\n",
    "\n",
    "- **Training Loss**: The AlmostFairKernelCRPS loss should decrease over time\n",
    "- **Validation Metrics**: Similar to training loss, calculated on validation data\n",
    "\n",
    "*Note:*\n",
    "------\n",
    "Typically the logging is done to a server and can be used interactively on a website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128d4b7-1a66-4cfa-a395-335115186f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tracking_uri = \"file:///home/student/aifs/logs/mlflow/\"\n",
    "run_id=\"138574957663430db3ca2e9d1468cf91\"\n",
    "\n",
    "# Start mlflow client and load run\n",
    "client = mlflow.tracking.MlflowClient(tracking_uri=\"file:///home/student/aifs/logs/mlflow/\")\n",
    "run = client.get_run(run_id)\n",
    "\n",
    "print(f\"Run name: {run.info.run_name}\")\n",
    "print(\"Logged metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for k in run.data.metrics.keys():\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc932b5-6934-42f0-afa8-18778a447615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "metric_names = ['train_afkcrps1.00_epoch', 'val_afkcrps1.00_epoch']\n",
    "\n",
    "# Load data into DataFrame\n",
    "data = []\n",
    "for metric in metric_names:\n",
    "    for entry in client.get_metric_history(run_id, metric):\n",
    "        data.append({'metric': metric, 'step': entry.step, 'value': entry.value, 'time': entry.timestamp})\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot all metrics\n",
    "fig, ax = plt.subplots()\n",
    "for metric in df['metric'].unique():\n",
    "    metric_data = df[df['metric'] == metric].sort_values('step')\n",
    "    ax.plot(metric_data['step'], metric_data['value'], '-o', label=metric)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12b7f8",
   "metadata": {},
   "source": [
    "### Task 1: Change the number of ensemble members\n",
    "\n",
    "Adapt the training config and retrain the model with:\n",
    "   - a larger number of ensemble members, e.g. `ensemble_size_per_device=4`\n",
    "   - train the model for longer by increasing the number of iterations (`max_steps`)\n",
    "\n",
    "**Questions**\n",
    "- How does your loss change with the same number of steps? \n",
    "- How much longer does the training take per iteration?\n",
    "- What happens if you choose a large number of ensemble members?\n",
    "\n",
    "***Note***:\n",
    "You do not need to do the training in the notebook. You can simply run on the console with \n",
    "```\n",
    "anemoi-training train --config-path ./config --config-name aifs_ens_minimal_config\n",
    "```\n",
    "\n",
    "### (Optional) Task 2: Inference of your model\n",
    "\n",
    "Run inference on the model you have trained. For that, go back to the Jupyter notebook `../4-run-AIFS/inference_aifs-ens.ipynb` and import your used checkpoint. \n",
    "\n",
    "***Note:***\n",
    "You need to adapt the resolution of the data for your input fields to O48\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a249b-e4a2-4536-a181-29362bae9d26",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef3fff-8c45-4a73-ab80-c06b4f2af50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
